{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "k = 1\n",
    "def sigmoid(x):\n",
    "    return 1.0/(1.0 + np.exp(-k*x))\n",
    "\n",
    "def sigmoid_prime(x):\n",
    "    return sigmoid(x)*(1.0-sigmoid(x))\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def tanh_prime(x):\n",
    "    return 1.0 - x**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 0\n",
      "epochs: 10000\n",
      "epochs: 20000\n",
      "epochs: 30000\n",
      "epochs: 40000\n",
      "epochs: 50000\n",
      "epochs: 60000\n",
      "epochs: 70000\n",
      "epochs: 80000\n",
      "epochs: 90000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAD8CAYAAABpcuN4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npKb/By9BkibMwYlYAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x22d08821630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0] [-0.00850833]\n",
      "[0 1] [ 0.99499197]\n",
      "[1 0] [ 0.99604369]\n",
      "[1 1] [-0.00554419]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class NeuralNetwork:\n",
    "\n",
    "    def __init__(self, layers):\n",
    "        self.activation = tanh\n",
    "        self.activation_prime = tanh_prime\n",
    "        # Set weights\n",
    "        self.weights = []\n",
    "        # layers = [2,2,1]\n",
    "        # range of weight values (-1,1)\n",
    "        # input and hidden layers - random((2+1, 2+1)) : 3 x 3\n",
    "        \n",
    "        for i in range(1, len(layers) - 1):\n",
    "            r = 2*np.random.random((layers[i-1] + 1, layers[i] + 1)) -1\n",
    "            self.weights.append(r)\n",
    "        # output layer - random((2+1, 1)) : 3 x 1\n",
    "        r = 2*np.random.random( (layers[i] + 1, layers[i+1])) - 1\n",
    "        self.weights.append(r)\n",
    "\n",
    "    def fit(self, X, y, learning_rate=0.2, epochs=100000):\n",
    "        # Add column of ones to X\n",
    "        # This is to add the bias unit to the input layer\n",
    "        ones = np.atleast_2d(np.ones(X.shape[0]))\n",
    "        X = np.concatenate((ones.T, X), axis=1)\n",
    "         \n",
    "        for k in range(epochs):\n",
    "            i = np.random.randint(X.shape[0])\n",
    "            a = [X[i]]\n",
    "\n",
    "            for l in range(len(self.weights)):\n",
    "                    dot_value = np.dot(a[l], self.weights[l])\n",
    "                    activation = self.activation(dot_value)\n",
    "                    a.append(activation)\n",
    "            # output layer\n",
    "            error = y[i] - a[-1]\n",
    "            deltas = [error * self.activation_prime(a[-1])]\n",
    "\n",
    "            # we need to begin at the second to last layer \n",
    "            # (a layer before the output layer)\n",
    "            for l in range(len(a) - 2, 0, -1): \n",
    "                deltas.append(deltas[-1].dot(self.weights[l].T)*self.activation_prime(a[l]))\n",
    "\n",
    "            # reverse\n",
    "            # [level3(output)->level2(hidden)]  => [level2(hidden)->level3(output)]\n",
    "            deltas.reverse()\n",
    "\n",
    "            # backpropagation\n",
    "            # 1. Multiply its output delta and input activation \n",
    "            #    to get the gradient of the weight.\n",
    "            # 2. Subtract a ratio (percentage) of the gradient from the weight.\n",
    "            for i in range(len(self.weights)):\n",
    "                layer = np.atleast_2d(a[i])\n",
    "                delta = np.atleast_2d(deltas[i])\n",
    "                self.weights[i] += learning_rate * layer.T.dot(delta)\n",
    "\n",
    "            if k % 10000 == 0: \n",
    "                print('epochs:', k)\n",
    "                \n",
    "        graph = plt.plot(error)\n",
    "        plt.show()\n",
    "    def predict(self, x): \n",
    "    \n",
    "        a = np.concatenate((np.ones(1).T, np.array(x)))      \n",
    "\n",
    "        for l in range(0, len(self.weights)):\n",
    "            a = self.activation(np.dot(a, self.weights[l]))\n",
    "        return a\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    nn = NeuralNetwork([2,2,1])\n",
    "    X = np.array([[0, 0],\n",
    "                  [0, 1],\n",
    "                  [1, 0],\n",
    "                  [1, 1]])\n",
    "    y = np.array([0, 1, 1, 0])\n",
    "#     X = np.array([[-1, -1],\n",
    "#                   [-1, 1],\n",
    "#                   [1, -1],\n",
    "#                   [1, 1]])\n",
    "#     y = np.array([0, 1, 1, 0])\n",
    "\n",
    "    nn.fit(X, y)\n",
    "    for e in X:\n",
    "        print(e,nn.predict(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
